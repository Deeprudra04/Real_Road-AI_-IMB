# -*- coding: utf-8 -*-
"""rice-leaf-disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JDOp__fXctFAqVRyLIKLgV5GF6gcfPFw
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import os
import random
import zipfile
import tensorflow as tf
from keras.layers import Input, Lambda, Dense, Flatten,GlobalAveragePooling2D,BatchNormalization,Dropout,Activation
from keras.models import Model
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
import numpy as np
from glob import glob
import matplotlib.pyplot as plt
import os
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, log_loss, accuracy_score
from sklearn.model_selection import train_test_split

"""**Reasoning**:
Import the necessary module and use the files.upload() function to allow the user to upload the dataset zip file.


"""

from google.colab import files

uploaded = files.upload()

"""## Extract the zip file

### Subtask:
Generate code to extract the contents of the uploaded zip file.

**Reasoning**:
The goal is to extract the contents of the uploaded zip file. The `zipfile` module is already imported. I will get the filename from the `uploaded` dictionary, open the zip file, extract its contents to a directory, and close the file.
"""

import os

# Get the filename of the uploaded zip file
zip_filename = list(uploaded.keys())[0]

# Create a directory to extract the contents
extracted_dir = "extracted_dataset"
os.makedirs(extracted_dir, exist_ok=True)

# Open the zip file and extract its contents
with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall(extracted_dir)

print(f"Extracted {zip_filename} to {extracted_dir}")

"""## Identify the extracted data path

### Subtask:
Guide the user to find the path where the dataset was extracted.

**Reasoning**:
List the contents of the extracted directory to find the main dataset folder and construct the full path.
"""

import os

# List the contents of the extracted_dataset directory
extracted_contents = os.listdir(extracted_dir)
print(f"Contents of {extracted_dir}: {extracted_contents}")

# Assuming the dataset is in a directory named 'RiceLeafsDisease' inside the extracted directory
dataset_directory_name = 'RiceLeafsDisease'
source_path = os.path.join(extracted_dir, dataset_directory_name)

print(f"The dataset is likely located at: {source_path}")

"""## Update the code

### Subtask:
Modify the existing code cells, particularly the one defining the `source_path`, to use the path to the extracted dataset.

**Reasoning**:
Modify the `source_path` variable in the existing code cell to point to the extracted dataset directory, which was identified as 'extracted_dataset/RiceLeafsDisease' in the previous step.

**Reasoning**:
The previous attempt to access the training data failed because the path was incorrect. I need to investigate the contents of the extracted directory again to confirm the correct path to the data.
"""

import os

# List the contents of the extracted_dataset directory
extracted_contents = os.listdir("extracted_dataset")
print(f"Contents of extracted_dataset: {extracted_contents}")

# List the contents of the directory within extracted_dataset (assuming it's RiceLeafsDisease)
if "RiceLeafsDisease" in extracted_contents:
    rice_leaf_contents = os.listdir(os.path.join("extracted_dataset", "RiceLeafsDisease"))
    print(f"Contents of extracted_dataset/RiceLeafsDisease: {rice_leaf_contents}")

"""**Reasoning**:
The previous output shows that the directory structure is `extracted_dataset/RiceLeafsDisease/train` and `extracted_dataset/RiceLeafsDisease/validation`. The `source_path` variable needs to point to `extracted_dataset/RiceLeafsDisease`. I will modify the code cell to correct the `source_path` and then rerun the code to list the number of images.

**Reasoning**:
The error persists even after confirming the directory structure. This indicates there might be an issue with how the paths are being constructed or accessed within the notebook environment. I will try listing the files directly within the expected training subdirectory to see if the files are actually present at that location.
"""

import os

# Define the expected path to the BrownSpot training images
brownspot_train_path = 'extracted_dataset/RiceLeafsDisease/train/BrownSpot'

# List the contents of the BrownSpot training directory
try:
    brownspot_files = os.listdir(brownspot_train_path)
    print(f"Contents of {brownspot_train_path}: {brownspot_files[:10]}...") # Print only the first 10 to avoid flooding output
except FileNotFoundError:
    print(f"Error: The directory '{brownspot_train_path}' was not found.")

"""**Reasoning**:
The previous check confirmed that the directory `extracted_dataset/RiceLeafsDisease/train/BrownSpot` does not exist. However, the previous output showed that `extracted_dataset/RiceLeafsDisease` contains 'train' and 'validation' directories. This implies that the subdirectories like 'BrownSpot' might be directly inside the 'train' and 'validation' directories without another 'RiceLeafsDisease' level. I need to confirm the correct nested structure. I will list the contents of the 'train' directory within 'extracted_dataset/RiceLeafsDisease'.


"""

import os

# Define the path to the train directory within the extracted dataset
train_dir_path = 'extracted_dataset/RiceLeafsDisease/train'

# List the contents of the train directory
try:
    train_contents = os.listdir(train_dir_path)
    print(f"Contents of {train_dir_path}: {train_contents}")
except FileNotFoundError:
    print(f"Error: The directory '{train_dir_path}' was not found.")

"""**Reasoning**:
The listing of the `train` directory contents revealed the actual subdirectory names: 'leaf_scald', 'brown_spot', 'bacterial_leaf_blight', 'narrow_brown_spot', 'leaf_blast', and 'healthy'. The original code was looking for 'BrownSpot', 'Healthy', 'Hispa', and 'LeafBlast'. I need to update the code cell to use the correct subdirectory names found in the `train` and `validation` directories and update the `source_path` to point to `extracted_dataset/RiceLeafsDisease` as the base path. I will then rerun the code to list the number of images using the corrected paths.


"""

source_path = 'extracted_dataset/RiceLeafsDisease'

# train source - using the correct subdirectory names
source_path_train_Brownspot = os.path.join(source_path, 'train/brown_spot')
source_path_train_Healthy   = os.path.join(source_path, 'train/healthy')
# Assuming 'Hispa' corresponds to 'bacterial_leaf_blight' or 'leaf_scald' or 'narrow_brown_spot' - need to check validation directory contents
# For now, I will use the names found in train and adjust if necessary after checking validation
source_path_train_Hispa     = os.path.join(source_path, 'train/bacterial_leaf_blight') # Assuming Hispa is bacterial_leaf_blight
source_path_train_LeafBlast = os.path.join(source_path, 'train/leaf_blast')
source_path_train_LeafScald = os.path.join(source_path, 'train/leaf_scald')
source_path_train_NarrowBrownSpot = os.path.join(source_path, 'train/narrow_brown_spot')


print(f"There are {len(os.listdir(source_path_train_Brownspot))} images of Train Brown Spot.")
print(f"There are {len(os.listdir(source_path_train_Healthy))} images of Train Healthy.")
print(f"There are {len(os.listdir(source_path_train_Hispa))} images of Train Bacterial Leaf Blight (Assuming Hispa).")
print(f"There are {len(os.listdir(source_path_train_LeafBlast))} images of Train Leaf Blast.")
print(f"There are {len(os.listdir(source_path_train_LeafScald))} images of Train Leaf Scald.")
print(f"There are {len(os.listdir(source_path_train_NarrowBrownSpot))} images of Train Narrow Brown Spot.\n")


# Validation source - need to check validation directory contents to confirm names
source_path_validation_dir = os.path.join(source_path, 'validation')
validation_contents = os.listdir(source_path_validation_dir)
print(f"Contents of {source_path_validation_dir}: {validation_contents}\n")

# Assuming validation directory has the same structure and names as train
source_path_validation_Brownspot  = os.path.join(source_path, 'validation/brown_spot')
source_path_validation_Healthy    = os.path.join(source_path, 'validation/healthy')
source_path_validation_Hispa      = os.path.join(source_path, 'validation/bacterial_leaf_blight') # Assuming Hispa is bacterial_leaf_blight in validation too
source_path_validation_LeafBlast  = os.path.join(source_path, 'validation/leaf_blast')
source_path_validation_LeafScald = os.path.join(source_path, 'validation/leaf_scald')
source_path_validation_NarrowBrownSpot = os.path.join(source_path, 'validation/narrow_brown_spot')


print(f"There are {len(os.listdir(source_path_validation_Brownspot))} images of Validation Brown Spot.")
print(f"There are {len(os.listdir(source_path_validation_Healthy))} images of Validation Healthy.")
print(f"There are {len(os.listdir(source_path_validation_Hispa))} images of Validation Bacterial Leaf Blight (Assuming Hispa).")
print(f"There are {len(os.listdir(source_path_validation_LeafBlast))} images of Validation Leaf Blast.")
print(f"There are {len(os.listdir(source_path_validation_LeafScald))} images of Validation Leaf Scald.")
print(f"There are {len(os.listdir(source_path_validation_NarrowBrownSpot))} images of Validation Narrow Brown Spot.\n")

"""**Reasoning**:
The previous output successfully listed the number of images in all the newly identified categories in both the training and validation sets, confirming that the `source_path` and the category subdirectory names are now correct. The next steps according to the instructions are to rerun the subsequent code cells that depend on `source_path` to ensure they are using the data from the extracted zip file. These cells include loading and preparing the dataset for model training.

**Reasoning**:
The error message `TypeError: load_img() got an unexpected keyword argument 'grayscale'` indicates that the `grayscale` argument is not supported by the current version of `load_img` being used. Based on the import statements, `load_img` is likely from `tensorflow.keras.preprocessing.image`. I need to remove the `grayscale=False` argument from the `load_img` calls in both the training and testing data loading loops as images are expected to be in RGB format, and `color_mode='rgb'` is already specified.
"""

# Rerun the code cells that depend on source_path with the corrected load_img call
# This includes the cells that define TRAINING_DIR, VALIDATION_DIR,
# load the dataset and testset, and prepare the data for training.

TRAINING_DIR = os.path.join(source_path, 'train')
VALIDATION_DIR = os.path.join(source_path, 'validation')

dataset = []
shape = (224, 224)
count = 0
# Update the loop to iterate through the correct subdirectories
for file in ['brown_spot', 'healthy', 'bacterial_leaf_blight', 'leaf_blast', 'leaf_scald', 'narrow_brown_spot']:
  path = os.path.join(TRAINING_DIR, file)
  time = 0
  for k in os.listdir(path):
    # Removed grayscale=False
    image   = load_img(os.path.join(path, k), color_mode='rgb', target_size = shape)
    image   = img_to_array(image)
    image   = image/255.0
    dataset += [[image, count]]
    time    +=1
  count = count+1

testset=[]
count=0
# Update the loop to iterate through the correct subdirectories
for file in ['brown_spot', 'healthy', 'bacterial_leaf_blight', 'leaf_blast', 'leaf_scald', 'narrow_brown_spot']:
    path=os.path.join(VALIDATION_DIR,file)
    t=0
    for im in os.listdir(path):
        # Removed grayscale=False
        image    = load_img(os.path.join(path,im), color_mode='rgb', target_size=shape)
        image    = img_to_array(image)
        image    = image/255.0
        testset  += [[image,count]]
        t        += 1
    count        = count+1

data,trainlabels = zip(*dataset)
test,testlabels = zip(*testset)

labels1 = to_categorical(trainlabels)
labels  = np.array(labels1)

data    = np.array(data)
test    = np.array(test)

trainx, testx, trainy, testy = train_test_split(data,
                                                labels,
                                                test_size=0.2,
                                                random_state=42)

print(trainx.shape)
print(testx.shape)
print(trainy.shape)
print(testy.shape)

"""## Continue with the rest of the notebook

### Subtask:
Continue with the subsequent steps in the notebook (data loading, preprocessing, model building, etc.) using the data from the uploaded zip file.

**Reasoning**:
Rerun the subsequent code cells for data augmentation, model definition, compilation, training, and saving, which depend on the successfully loaded and split data.
"""

# Rerun data augmentation setup
train_datagen = ImageDataGenerator(horizontal_flip=True,
                             vertical_flip=True,
                             rotation_range=30,
                             zoom_range=0.2,
                             width_shift_range=0.1,
                             height_shift_range=0.2,
                             shear_range=0.2)

# Rerun model definition (DenseNet121 base with custom layers)
pretrained_model = tf.keras.applications.DenseNet121(input_shape=(224,224,3),
                                                      include_top=False,
                                                      weights='imagenet')

inputs = pretrained_model.input
x = tf.keras.layers.Flatten()(pretrained_model.output)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dropout(0.2)(x)
# Update the output layer dense units to match the number of classes (6 instead of 4)
outputs = tf.keras.layers.Dense(6, activation='softmax')(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)

# Rerun model compilation
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Rerun model training
# Adjust epochs if needed, but keep it reasonable for demonstration
his=model.fit(train_datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=10, verbose=1)

# Rerun plotting of training history
get_acc = his.history['accuracy']
value_acc = his.history['val_accuracy']
get_loss = his.history['loss']
validation_loss = his.history['val_loss']

epochs = range(len(get_acc))
plt.plot(epochs, get_acc, 'r', label='Accuracy of Training data')
plt.plot(epochs, value_acc, 'b', label='Accuracy of Validation data')
plt.title('Training vs validation accuracy')
plt.legend(loc=0)
plt.figure()
plt.show()

# Rerun TFLite model conversion and saving
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

import pathlib
tflite_models_dir = pathlib.Path("tflite_models/")
tflite_models_dir.mkdir(exist_ok=True, parents=True)

tflite_model_file = tflite_models_dir/"model.tflite"
tflite_model_file.write_bytes(tflite_model)

converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_quant_model = converter.convert()
tflite_model_quant_file = tflite_models_dir/"model_quant.tflite"
tflite_model_quant_file.write_bytes(tflite_quant_model)

# Verify saved files
!ls -lh {tflite_models_dir}

"""## Summary:

### Data Analysis Key Findings

*   The dataset was successfully uploaded as a zip file and extracted into a directory named `extracted_dataset`.
*   The extracted contents included a primary dataset directory named `RiceLeafsDisease`.
*   Within `RiceLeafsDisease`, there were `train` and `validation` subdirectories.
*   The `train` and `validation` directories contained six subdirectories each, corresponding to the image classes: 'leaf\_scald', 'brown\_spot', 'bacterial\_leaf\_blight', 'narrow\_brown\_spot', 'leaf\_blast', and 'healthy'.
*   The code successfully updated the `source_path` variable to `'extracted_dataset/RiceLeafsDisease'`.
*   The data loading and preprocessing steps were successfully adapted to use the extracted data and the correct subdirectory names.
*   The `load_img` function was updated by removing the incompatible `grayscale=False` argument.
*   The model's output layer was correctly configured with 6 units to match the number of classes in the dataset.
*   Model training commenced successfully using the extracted and processed data.
*   The model was successfully saved in both standard and quantized TFLite formats.

### Insights or Next Steps

*   The training process is underway, and its completion will provide metrics on the model's performance on the extracted dataset.
*   The saved TFLite models can now be used for deployment on edge devices or other platforms.

Once you run the cell above and authorize Colab to access your Google Drive, your Drive will be mounted at `/content/drive`. You can then access your files using paths starting with `/content/drive/My Drive/`.

For example, if your dataset zip file is in a folder named `datasets` in your Drive, the path would be `/content/drive/My Drive/datasets/your_dataset.zip`. You would then use this path for extraction.
"""